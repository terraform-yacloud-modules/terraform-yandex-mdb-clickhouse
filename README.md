# Yandex Cloud ClickHouse Terraform module

Terraform module which creates Yandex Cloud ClickHouse resources.

Fork of https://github.com/polina-yudina/terraform-yc-clickhouse

## Examples

Examples codified under
the [`examples`](https://github.com/terraform-yacloud-modules/terraform-yandex-module-template/tree/main/examples) are intended
to give users references for how to use the module(s) as well as testing/validating changes to the source code of the
module. If contributing to the project, please be sure to make any appropriate updates to the relevant examples to allow
maintainers to test your changes and to keep the examples up to date for users. Thank you!

<!-- BEGIN_TF_DOCS -->
## Requirements

| Name | Version |
|------|---------|
| <a name="requirement_terraform"></a> [terraform](#requirement\_terraform) | >= 1.0.0 |
| <a name="requirement_random"></a> [random](#requirement\_random) | > 3.3 |
| <a name="requirement_yandex"></a> [yandex](#requirement\_yandex) | > 0.8 |

## Providers

| Name | Version |
|------|---------|
| <a name="provider_random"></a> [random](#provider\_random) | > 3.3 |
| <a name="provider_yandex"></a> [yandex](#provider\_yandex) | > 0.8 |

## Modules

No modules.

## Resources

| Name | Type |
|------|------|
| [random_password.password](https://registry.terraform.io/providers/hashicorp/random/latest/docs/resources/password) | resource |
| [yandex_mdb_clickhouse_cluster.this](https://registry.terraform.io/providers/yandex-cloud/yandex/latest/docs/resources/mdb_clickhouse_cluster) | resource |
| [yandex_client_config.client](https://registry.terraform.io/providers/yandex-cloud/yandex/latest/docs/data-sources/client_config) | data source |

## Inputs

| Name | Description | Type | Default | Required |
|------|-------------|------|---------|:--------:|
| <a name="input_access"></a> [access](#input\_access) | (Optional) Access policy from other services to the ClickHouse cluster.<br/><br/>    Default: null | <pre>object({<br/>    data_lens     = optional(bool, null)<br/>    metrika       = optional(bool, null)<br/>    web_sql       = optional(bool, null)<br/>    serverless    = optional(bool, null)<br/>    yandex_query  = optional(bool, null)<br/>    data_transfer = optional(bool, null)<br/>  })</pre> | `{}` | no |
| <a name="input_admin_password"></a> [admin\_password](#input\_admin\_password) | (Optional) A password used to authorize as user admin when sql\_user\_management enabled.<br/><br/>    Default: null | `string` | `null` | no |
| <a name="input_backup_window_start"></a> [backup\_window\_start](#input\_backup\_window\_start) | (Optional) Time to start the daily backup, in the UTC timezone.<br/><br/>    Default: null | <pre>object({<br/>    hours   = string<br/>    minutes = optional(string, "00")<br/>  })</pre> | `null` | no |
| <a name="input_clickhouse_config"></a> [clickhouse\_config](#input\_clickhouse\_config) | (Optional) Main ClickHouse cluster configuration. For more information, see the official documentation.<br/>    Link 1: https://cloud.yandex.com/en-ru/docs/managed-clickhouse/concepts/settings-list<br/>    Link 2: https://registry.terraform.io/providers/yandex-cloud/yandex/latest/docs/resources/mdb_clickhouse_cluster#config | <pre>object({<br/>    background_fetches_pool_size    = optional(number, 0)<br/>    background_pool_size            = optional(number, 0)<br/>    background_schedule_pool_size   = optional(number, 0)<br/>    default_database                = optional(string, "")<br/>    geobase_uri                     = optional(string, "")<br/>    keep_alive_timeout              = optional(number, 3)<br/>    log_level                       = optional(string, "DEBUG")<br/>    mark_cache_size                 = optional(number, 5368709120)<br/>    max_concurrent_queries          = optional(number, 500)<br/>    max_connections                 = optional(number, 4096)<br/>    max_partition_size_to_drop      = optional(number, 53687091200)<br/>    max_table_size_to_drop          = optional(number, 53687091200)<br/>    metric_log_enabled              = optional(bool, true)<br/>    metric_log_retention_size       = optional(number, 536870912)<br/>    metric_log_retention_time       = optional(number, 2592000000)<br/>    part_log_retention_size         = optional(number, 536870912)<br/>    part_log_retention_time         = optional(number, 2592000000)<br/>    query_log_retention_size        = optional(number, 1073741824)<br/>    query_log_retention_time        = optional(number, 2592000000)<br/>    query_thread_log_enabled        = optional(bool, true)<br/>    query_thread_log_retention_size = optional(number, 536870912)<br/>    query_thread_log_retention_time = optional(number, 2592000000)<br/>    text_log_enabled                = optional(bool, false)<br/>    text_log_level                  = optional(string, "TRACE")<br/>    text_log_retention_size         = optional(number, 536870912)<br/>    text_log_retention_time         = optional(number, 2592000000)<br/>    timezone                        = optional(string, "Europe/Moscow")<br/>    total_memory_profiler_step      = optional(number, 0)<br/>    trace_log_enabled               = optional(bool, true)<br/>    trace_log_retention_size        = optional(number, 536870912)<br/>    trace_log_retention_time        = optional(number, 2592000000)<br/>    uncompressed_cache_size         = optional(number, 8589934592)<br/>    compression = optional(object({<br/>      method              = optional(string, null)<br/>      min_part_size       = optional(number, null)<br/>      min_part_size_ratio = optional(number, null)<br/>    }), null)<br/>    graphite_rollup = optional(object({<br/>      name = string<br/>      pattern = object({<br/>        function = string<br/>        regexp   = optional(string, null)<br/>        retention = object({<br/>          age       = number<br/>          precision = number<br/>        })<br/>      })<br/>    }), null)<br/>    kafka = optional(object({<br/>      security_protocol = optional(string, null)<br/>      sasl_mechanism    = optional(string, null)<br/>      sasl_username     = optional(string, null)<br/>      sasl_password     = optional(string, null)<br/>    }), null)<br/>    kafka_topic = optional(object({<br/>      name = string<br/>      settings = optional(object({<br/>        security_protocol = optional(string, null)<br/>        sasl_mechanism    = optional(string, null)<br/>        sasl_username     = optional(string, null)<br/>        sasl_password     = optional(string, null)<br/>      }), null)<br/>    }), null)<br/>    merge_tree = optional(object({<br/>      max_bytes_to_merge_at_min_space_in_pool                   = optional(number, 53687091200)<br/>      max_replicated_merges_in_queue                            = optional(number, 16)<br/>      min_bytes_for_wide_part                                   = optional(number, 0)<br/>      min_rows_for_wide_part                                    = optional(number, 0)<br/>      number_of_free_entries_in_pool_to_lower_max_size_of_merge = optional(number, 8)<br/>      parts_to_delay_insert                                     = optional(number, 150)<br/>      parts_to_throw_insert                                     = optional(number, 300)<br/>      replicated_deduplication_window                           = optional(number, 100)<br/>      replicated_deduplication_window_seconds                   = optional(number, 604800)<br/>      ttl_only_drop_parts                                       = optional(bool, false)<br/>    }), null)<br/>    rabbitmq = optional(object({<br/>      username = optional(string, "")<br/>      password = optional(string, "")<br/>      vhost    = optional(string, "")<br/>    }), null)<br/>  })</pre> | `null` | no |
| <a name="input_clickhouse_disk_size"></a> [clickhouse\_disk\_size](#input\_clickhouse\_disk\_size) | (Optional) Disk size for hosts.<br/><br/>    Default: 10 | `number` | `10` | no |
| <a name="input_clickhouse_disk_type_id"></a> [clickhouse\_disk\_type\_id](#input\_clickhouse\_disk\_type\_id) | (Optional) Disk type for hosts.<br/><br/>    Allowed types:<br/>      - network-hdd<br/>      - network-ssd<br/>      - network-ssd-nonreplicated<br/>      - local-ssd<br/><br/>    "local-ssd" restrictions:<br/>      - For Intel Broadwell and Intel Cascade Lake: Only in increments of 100 GB.<br/>      - For Intel Ice Lake: Only in increments of 368 GB.<br/><br/>    Default: "network-ssd" | `string` | `"network-ssd"` | no |
| <a name="input_clickhouse_resource_preset_id"></a> [clickhouse\_resource\_preset\_id](#input\_clickhouse\_resource\_preset\_id) | (Optional) Preset for hosts.<br/>    All types: https://cloud.yandex.com/en/docs/managed-clickhouse/concepts/instance-types<br/><br/>    Default: "s3-c2-m8" | `string` | `"s3-c2-m8"` | no |
| <a name="input_clickhouse_version"></a> [clickhouse\_version](#input\_clickhouse\_version) | (Optional) ClickHouse version.<br/><br/>    Default: "24.8" | `string` | `"24.8"` | no |
| <a name="input_cloud_storage"></a> [cloud\_storage](#input\_cloud\_storage) | - enabled             - (Required) Whether to use Yandex Object Storage for storing ClickHouse data. Can be either true or false.<br/>    - move\_factor         - (Optional) Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.<br/>    - data\_cache\_enabled  - (Optional) Enables temporary storage in the cluster repository of data requested from the object repository.<br/>    - data\_cache\_max\_size - (Optional) Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.<br/><br/>    Default: null | <pre>object({<br/>    enabled             = optional(bool, false)<br/>    move_factor         = optional(number, 0)<br/>    data_cache_enabled  = optional(bool, false)<br/>    data_cache_max_size = optional(number, 0)<br/>  })</pre> | `null` | no |
| <a name="input_copy_schema_on_new_hosts"></a> [copy\_schema\_on\_new\_hosts](#input\_copy\_schema\_on\_new\_hosts) | (Optional) Whether to copy schema on new ClickHouse hosts.<br/><br/>    Default: false | `bool` | `false` | no |
| <a name="input_databases"></a> [databases](#input\_databases) | (Required) A list of ClickHouse databases.<br/><br/>    Required values:<br/>      - name - The name of the database. | <pre>list(object({<br/>    name = string<br/>  }))</pre> | `[]` | no |
| <a name="input_deletion_protection"></a> [deletion\_protection](#input\_deletion\_protection) | (Optional) Inhibits deletion of the cluster.<br/><br/>    Default: false | `bool` | `false` | no |
| <a name="input_description"></a> [description](#input\_description) | (Optional) ClickHouse cluster description.<br/><br/>    Default: null | `string` | `null` | no |
| <a name="input_embedded_keeper"></a> [embedded\_keeper](#input\_embedded\_keeper) | (Optional, ForceNew) Whether to use ClickHouse Keeper as a coordination system and place it on the same hosts with ClickHouse. If not, it's used ZooKeeper with placement on separate hosts.<br/><br/>    Default: false | `bool` | `false` | no |
| <a name="input_environment"></a> [environment](#input\_environment) | (Optional) Environment type: "PRODUCTION" or "PRESTABLE".<br/><br/>    Default: "PRODUCTION" | `string` | `"PRODUCTION"` | no |
| <a name="input_folder_id"></a> [folder\_id](#input\_folder\_id) | (Optional) Folder id that contains the ClickHouse cluster.<br/><br/>    Default: null | `string` | `null` | no |
| <a name="input_format_schema"></a> [format\_schema](#input\_format\_schema) | (Optional) A set of protobuf or capnproto format schemas.<br/>    - name - (Required) The name of the ml model.<br/>    - type - (Required) Type of the model.<br/>    - uri  - (Required) Model file URL. You can only use models stored in Yandex Object Storage.<br/><br/>    Default: null | <pre>object({<br/>    name = string<br/>    type = string<br/>    uri  = string<br/>  })</pre> | `null` | no |
| <a name="input_hosts"></a> [hosts](#input\_hosts) | (Required) A list of ClickHouse hosts.<br/>    - type - (Required) The type of the host to be deployed. Can be either "CLICKHOUSE" or "ZOOKEEPER".<br/>    - zone  - (Required) The availability zone where the ClickHouse host will be created. Allowed values: "ru-central1-a", "ru-central1-b", "ru-central1-c".<br/>    - subnet\_id - (Optional) The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.<br/>    - shard\_name - (Optional) The name of the shard to which the host belongs.<br/>    - assign\_public\_ip - (Optional) Sets whether the host should get a public IP address on creation. Can be either true or false. | <pre>list(object({<br/>    type             = string<br/>    zone             = string<br/>    subnet_id        = optional(string, null)<br/>    shard_name       = optional(string, null)<br/>    assign_public_ip = optional(bool, null)<br/>  }))</pre> | `[]` | no |
| <a name="input_labels"></a> [labels](#input\_labels) | (Optional) A set of label pairs to assign to the ClickHouse cluster.<br/><br/>    Default: {} | `map(any)` | `{}` | no |
| <a name="input_maintenance_window"></a> [maintenance\_window](#input\_maintenance\_window) | (Optional) Maintenance policy of the ClickHouse cluster.<br/>    - type - (Required) Type of maintenance window. Can be either ANYTIME or WEEKLY. A day and hour of window need to be specified with weekly window.<br/>    - day  - (Optional) Day of the week (in DDD format). Allowed values: "MON", "TUE", "WED", "THU", "FRI", "SAT", "SUN"<br/>    - hour - (Optional) Hour of the day in UTC (in HH format). Allowed value is between 0 and 23.<br/><br/>    Default: {type = "ANYTIME"} | <pre>object({<br/>    type = string<br/>    day  = optional(string, null)<br/>    hour = optional(string, null)<br/>  })</pre> | <pre>{<br/>  "type": "ANYTIME"<br/>}</pre> | no |
| <a name="input_ml_model"></a> [ml\_model](#input\_ml\_model) | (Optional) A group of machine learning models.<br/>    - name - (Required) The name of the ml model.<br/>    - type - (Required) Type of the model.<br/>    - uri - (Required) Model file URL. You can only use models stored in Yandex Object Storage.<br/><br/>    Default: null | <pre>object({<br/>    name = string<br/>    type = string<br/>    uri  = string<br/>  })</pre> | `null` | no |
| <a name="input_name"></a> [name](#input\_name) | (Optional) Name of ClickHouse cluster.<br/><br/>    Default: "clickhouse-cluster" | `string` | `"clickhouse-cluster"` | no |
| <a name="input_network_id"></a> [network\_id](#input\_network\_id) | (Required) ClickHouse cluster network id | `string` | n/a | yes |
| <a name="input_security_group_ids"></a> [security\_group\_ids](#input\_security\_group\_ids) | (Optional) A list of security group IDs to which the ClickHouse cluster belongs.<br/><br/>    Default: [] | `list(string)` | `[]` | no |
| <a name="input_shard_group"></a> [shard\_group](#input\_shard\_group) | (Optional) A group of clickhouse shards.<br/>    - name - (Required) - The name of the shard group, used as cluster name in Distributed tables.<br/>    - shard\_names - (Required) - List of shards names that belong to the shard group.<br/>    - description - (Optional) - Description of the shard group.<br/><br/>    Default: null | <pre>object({<br/>    name        = string<br/>    shard_names = list(string)<br/>    description = optional(string, "")<br/>  })</pre> | `null` | no |
| <a name="input_shards"></a> [shards](#input\_shards) | - name      - (Required) The name of shard.<br/>    - weight    - (Optional) The weight of shard.<br/>    - resources - (Optional) Resources allocated to host of the shard. The resources specified for the shard takes precedence over the resources specified for the cluster. .<br/>      - resource\_preset\_id - Preset for hosts.<br/>      - disk\_size          - Disk size for hosts<br/>      - disk\_type\_id       - Disk type for hosts. One of: "network-hdd", "network-ssd", "network-ssd-nonreplicated", "local-ssd".<br/><br/>    Default: [] | <pre>list(object({<br/>    name   = string<br/>    weight = optional(number, null)<br/>    resources = optional(object({<br/>      resource_preset_id = string<br/>      disk_size          = number<br/>      disk_type_id       = string<br/>    }), null)<br/>  }))</pre> | `[]` | no |
| <a name="input_sql_database_management"></a> [sql\_database\_management](#input\_sql\_database\_management) | (Optional, ForceNew) Grants admin user database management permission.<br/><br/>    Default: false | `bool` | `false` | no |
| <a name="input_sql_user_management"></a> [sql\_user\_management](#input\_sql\_user\_management) | (Optional, ForceNew) Enables admin user with user management permission.<br/><br/>    Default: false | `bool` | `false` | no |
| <a name="input_timeouts"></a> [timeouts](#input\_timeouts) | Timeout settings for cluster operations | <pre>object({<br/>    create = optional(string)<br/>    update = optional(string)<br/>    delete = optional(string)<br/>  })</pre> | `null` | no |
| <a name="input_users"></a> [users](#input\_users) | (Required) This is a list for additional ClickHouse users with own permissions.<br/><br/>    Required values:<br/>      - name                - The name of the user.<br/>      - password            - The user's password. If it's omitted a random password will be generated<br/><br/>    Optional values:<br/>      - permission          - Set of permissions granted to the user. .<br/>        - database\_name     - (Required) The name of the database that the permission grants access to.<br/>      - settings            - Custom settings for user. The list is documented below.<br/>                              All options by link: https://registry.terraform.io/providers/yandex-cloud/yandex/latest/docs/resources/mdb_clickhouse_cluster#settings<br/>      - quota               - Set of user quotas. .<br/>        - interval\_duration - (Required) Duration of interval for quota in milliseconds.<br/>        - queries           - (Optional) The total number of queries.<br/>        - errors            - (Optional) The number of queries that threw exception.<br/>        - result\_rows       - (Optional) The total number of rows given as the result.<br/>        - read\_rows         - (Optional) The total number of source rows read from tables for running the query, on all remote servers.<br/>        - execution\_time    - (Optional) The total query execution time, in milliseconds (wall time). | <pre>list(object({<br/>    name     = string<br/>    password = optional(string)<br/>    quota = optional(list(object({<br/>      interval_duration = string<br/>      queries           = optional(number, null)<br/>      errors            = optional(number, null)<br/>      result_rows       = optional(number, null)<br/>      read_rows         = optional(number, null)<br/>      execution_time    = optional(number, null)<br/>    })), [])<br/>    permission = optional(list(object({<br/>      database_name = string<br/>    })), [])<br/>    settings = optional(object({<br/>      add_http_cors_header                               = optional(bool, false)<br/>      allow_ddl                                          = optional(bool, false)<br/>      allow_introspection_functions                      = optional(bool, false)<br/>      allow_suspicious_low_cardinality_types             = optional(bool, false)<br/>      async_insert                                       = optional(bool, false)<br/>      async_insert_busy_timeout                          = optional(number, 0)<br/>      async_insert_max_data_size                         = optional(number, 0)<br/>      async_insert_stale_timeout                         = optional(number, 0)<br/>      async_insert_threads                               = optional(number, 0)<br/>      cancel_http_readonly_queries_on_client_close       = optional(bool, false)<br/>      compile                                            = optional(bool, false)<br/>      compile_expressions                                = optional(bool, false)<br/>      connect_timeout                                    = optional(number, 0)<br/>      connect_timeout_with_failover                      = optional(number, 0)<br/>      count_distinct_implementation                      = optional(string, "unspecified")<br/>      distinct_overflow_mode                             = optional(string, "unspecified")<br/>      distributed_aggregation_memory_efficient           = optional(bool, false)<br/>      distributed_ddl_task_timeout                       = optional(number, 0)<br/>      distributed_product_mode                           = optional(string, "unspecified")<br/>      empty_result_for_aggregation_by_empty_set          = optional(bool, false)<br/>      enable_http_compression                            = optional(bool, false)<br/>      fallback_to_stale_replicas_for_distributed_queries = optional(bool, false)<br/>      flatten_nested                                     = optional(bool, false)<br/>      force_index_by_date                                = optional(bool, false)<br/>      force_primary_key                                  = optional(bool, false)<br/>      group_by_overflow_mode                             = optional(string, "unspecified")<br/>      group_by_two_level_threshold                       = optional(number, 0)<br/>      group_by_two_level_threshold_bytes                 = optional(number, 0)<br/>      http_connection_timeout                            = optional(number, 0)<br/>      http_headers_progress_interval                     = optional(number, 0)<br/>      http_receive_timeout                               = optional(number, 0)<br/>      http_send_timeout                                  = optional(number, 0)<br/>      input_format_defaults_for_omitted_fields           = optional(bool, false)<br/>      input_format_values_interpret_expressions          = optional(bool, false)<br/>      insert_null_as_default                             = optional(bool, false)<br/>      insert_quorum                                      = optional(number, 0)<br/>      insert_quorum_timeout                              = optional(number, 0)<br/>      join_overflow_mode                                 = optional(string, "unspecified")<br/>      join_use_nulls                                     = optional(bool, false)<br/>      joined_subquery_requires_alias                     = optional(bool, false)<br/>      low_cardinality_allow_in_native_format             = optional(bool, false)<br/>      max_ast_depth                                      = optional(number, 0)<br/>      max_ast_elements                                   = optional(number, 0)<br/>      max_block_size                                     = optional(number, 0)<br/>      max_bytes_before_external_group_by                 = optional(number, 0)<br/>      max_bytes_before_external_sort                     = optional(number, 0)<br/>      max_bytes_in_distinct                              = optional(number, 0)<br/>      max_bytes_in_join                                  = optional(number, 0)<br/>      max_bytes_in_set                                   = optional(number, 0)<br/>      max_bytes_to_read                                  = optional(number, 0)<br/>      max_bytes_to_sort                                  = optional(number, 0)<br/>      max_bytes_to_transfer                              = optional(number, 0)<br/>      max_columns_to_read                                = optional(number, 0)<br/>      max_concurrent_queries_for_user                    = optional(number, 0)<br/>      max_execution_time                                 = optional(number, 0)<br/>      max_expanded_ast_elements                          = optional(number, 0)<br/>      max_http_get_redirects                             = optional(number, 0)<br/>      max_insert_block_size                              = optional(number, 0)<br/>      max_memory_usage                                   = optional(number, 0)<br/>      max_memory_usage_for_user                          = optional(number, 0)<br/>      max_network_bandwidth                              = optional(number, 0)<br/>      max_network_bandwidth_for_user                     = optional(number, 0)<br/>      max_query_size                                     = optional(number, 0)<br/>      max_replica_delay_for_distributed_queries          = optional(number, 0)<br/>      max_result_bytes                                   = optional(number, 0)<br/>      max_result_rows                                    = optional(number, 0)<br/>      max_rows_in_distinct                               = optional(number, 0)<br/>      max_rows_in_join                                   = optional(number, 0)<br/>      max_rows_in_set                                    = optional(number, 0)<br/>      max_rows_to_group_by                               = optional(number, 0)<br/>      max_rows_to_read                                   = optional(number, 0)<br/>      max_rows_to_sort                                   = optional(number, 0)<br/>      max_rows_to_transfer                               = optional(number, 0)<br/>      max_temporary_columns                              = optional(number, 0)<br/>      max_temporary_non_const_columns                    = optional(number, 0)<br/>      max_threads                                        = optional(number, 0)<br/>      memory_profiler_sample_probability                 = optional(number, 0)<br/>      memory_profiler_step                               = optional(number, 0)<br/>      merge_tree_max_bytes_to_use_cache                  = optional(number, 0)<br/>      merge_tree_max_rows_to_use_cache                   = optional(number, 0)<br/>      merge_tree_min_bytes_for_concurrent_read           = optional(number, 0)<br/>      merge_tree_min_rows_for_concurrent_read            = optional(number, 0)<br/>      min_bytes_to_use_direct_io                         = optional(number, 0)<br/>      min_count_to_compile                               = optional(number, 0)<br/>      min_count_to_compile_expression                    = optional(number, 0)<br/>      min_execution_speed                                = optional(number, 0)<br/>      min_execution_speed_bytes                          = optional(number, 0)<br/>      min_insert_block_size_bytes                        = optional(number, 0)<br/>      min_insert_block_size_rows                         = optional(number, 0)<br/>      output_format_json_quote_64bit_integers            = optional(bool, false)<br/>      output_format_json_quote_denormals                 = optional(bool, false)<br/>      priority                                           = optional(number, 0)<br/>      quota_mode                                         = optional(string, "unspecified")<br/>      read_overflow_mode                                 = optional(string, "unspecified")<br/>      readonly                                           = optional(number, 0)<br/>      receive_timeout                                    = optional(number, 0)<br/>      replication_alter_partitions_sync                  = optional(number, 0)<br/>      result_overflow_mode                               = optional(string, "unspecified")<br/>      select_sequential_consistency                      = optional(bool, false)<br/>      send_progress_in_http_headers                      = optional(bool, false)<br/>      send_timeout                                       = optional(number, 0)<br/>      set_overflow_mode                                  = optional(string, "unspecified")<br/>      skip_unavailable_shards                            = optional(bool, false)<br/>      sort_overflow_mode                                 = optional(string, "unspecified")<br/>      timeout_before_checking_execution_speed            = optional(number, 0)<br/>      timeout_overflow_mode                              = optional(string, "unspecified")<br/>      transfer_overflow_mode                             = optional(string, "unspecified")<br/>      transform_null_in                                  = optional(bool, false)<br/>      use_uncompressed_cache                             = optional(bool, false)<br/>      wait_for_async_insert                              = optional(bool, false)<br/>      wait_for_async_insert_timeout                      = optional(number, 0)<br/>    }), null)<br/>  }))</pre> | `[]` | no |
| <a name="input_zookeeper_disk_size"></a> [zookeeper\_disk\_size](#input\_zookeeper\_disk\_size) | (Optional) Volume of the storage available to a ZooKeeper host, in gigabytes.<br/><br/>    Default: 0 | `number` | `0` | no |
| <a name="input_zookeeper_disk_type_id"></a> [zookeeper\_disk\_type\_id](#input\_zookeeper\_disk\_type\_id) | (Optional) Type of the storage of ZooKeeper hosts.<br/><br/>    Allowed types:<br/>      - network-hdd<br/>      - network-ssd<br/>      - network-ssd-nonreplicated<br/>      - local-ssd<br/><br/>    "local-ssd" restrictions:<br/>      - For Intel Broadwell and Intel Cascade Lake: Only in increments of 100 GB.<br/>      - For Intel Ice Lake: Only in increments of 368 GB.<br/><br/>    For more information see the official documentation.<br/>    Link: https://cloud.yandex.com/en-ru/docs/managed-clickhouse/concepts/storage<br/><br/>    Default: "" | `string` | `""` | no |
| <a name="input_zookeeper_resource_preset_id"></a> [zookeeper\_resource\_preset\_id](#input\_zookeeper\_resource\_preset\_id) | (Optional) The ID of the preset for computational resources available to a ZooKeeper host (CPU, memory etc.). For more information, see the official documentation.<br/>    Link: https://cloud.yandex.com/en/docs/managed-clickhouse/concepts/instance-types<br/><br/>    Default: "" | `string` | `""` | no |

## Outputs

| Name | Description |
|------|-------------|
| <a name="output_cluster_fqdns_list"></a> [cluster\_fqdns\_list](#output\_cluster\_fqdns\_list) | ClickHouse cluster nodes FQDN list. |
| <a name="output_cluster_host_zones_list"></a> [cluster\_host\_zones\_list](#output\_cluster\_host\_zones\_list) | ClickHouse cluster host zones. |
| <a name="output_cluster_id"></a> [cluster\_id](#output\_cluster\_id) | ClickHouse cluster ID. |
| <a name="output_cluster_name"></a> [cluster\_name](#output\_cluster\_name) | ClickHouse cluster name. |
| <a name="output_cluster_users"></a> [cluster\_users](#output\_cluster\_users) | A list of users with passwords. |
| <a name="output_connection"></a> [connection](#output\_connection) | How connect to ClickHouse cluster?<br/><br/>    1. Install certificate<br/><br/>      mkdir -p /usr/local/share/ca-certificates/Yandex/ && \\<br/>      wget "https://storage.yandexcloud.net/cloud-certs/CA.pem" -O /usr/local/share/ca-certificates/Yandex/YandexInternalRootCA.crt && \\<br/>      chmod 0655 /usr/local/share/ca-certificates/Yandex/YandexInternalRootCA.crt<br/><br/>    2. Upload config.<br/><br/>      mkdir --parents ~/.clickhouse-client && \\<br/>      wget "https://storage.yandexcloud.net/doc-files/clickhouse-client.conf.example" -O ~/.clickhouse-client/config.xml<br/><br/>    3. Run connection string from the output value, for example<br/><br/>      clickhouse-client --host rc1a-xxxxxxxxxxxxxxxx.mdb.yandexcloud.net \<br/>                  --secure \<br/>                  --user user\_name \<br/>                  --database database\_name \<br/>                  --port 9440 \<br/>                  --ask-password |
| <a name="output_databases"></a> [databases](#output\_databases) | A list of databases names. |
<!-- END_TF_DOCS -->

## License

Apache-2.0 Licensed.
See [LICENSE](https://github.com/terraform-yacloud-modules/terraform-yandex-module-template/blob/main/LICENSE).
